import requests
from bs4 import BeautifulSoup
import html2text
import re
import gradio as gr
from theme import create_zen_theme
import tempfile
import os
import zipfile
from urllib.parse import urlparse, unquote

def scrape_wikipedia_to_markdown_final(url: str) -> str:
    """
    Wikipediaãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ã€æ•´å½¢ãƒ»ä¸è¦éƒ¨åˆ†å‰Šé™¤ã‚’è¡Œã„ã€
    ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»˜ã‘ã¦Markdownã«å¤‰æ›ã—ã¾ã™ã€‚

    å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼š
    1. ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’H1è¦‹å‡ºã—ã¨ã—ã¦å–å¾—ã—ã¾ã™ã€‚
    2. ã€Œç™»å ´äººç‰©ã€ãªã©ã®<dt>ã‚¿ã‚°ã‚’è¦‹å‡ºã—ã«å¤‰æ›ã—ã¾ã™ã€‚
    3. ç”Ÿæˆã•ã‚ŒãŸMarkdownæ–‡å­—åˆ—ã‹ã‚‰ã€Œ## è„šæ³¨ã€ä»¥é™ã‚’å®Œå…¨ã«å‰Šé™¤ã—ã¾ã™ã€‚
    4. [ç·¨é›†]ãƒªãƒ³ã‚¯ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
    5. æœ€çµ‚çš„ã«ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’çµåˆã—ã¦è¿”ã—ã¾ã™ã€‚

    Args:
        url (str): ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®Wikipediaãƒšãƒ¼ã‚¸ã®URLã€‚

    Returns:
        str: æ•´å½¢ãƒ»å¤‰æ›ã•ã‚ŒãŸæœ€çµ‚çš„ãªMarkdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€‚å¤±æ•—ã—ãŸå ´åˆã¯ç©ºã®æ–‡å­—åˆ—ã€‚
    """
    try:
        # 1. HTMLã®å–å¾—ã¨è§£æ
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹
        response.encoding = response.apparent_encoding  # æ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•æ¤œå‡º
        soup = BeautifulSoup(response.text, 'html.parser')

        # --- ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾— ---
        title_tag = soup.find('h1', id='firstHeading')
        page_title = title_tag.get_text(strip=True) if title_tag else "Wikipedia ãƒšãƒ¼ã‚¸"

        # 2. ä¸»è¦ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ã®ç‰¹å®š
        content_div = soup.find('div', class_='mw-parser-output')
        if not content_div:
            return "ã‚¨ãƒ©ãƒ¼: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

        # 3. HTMLã®äº‹å‰æ•´å½¢ï¼ˆç™»å ´äººç‰©ãªã©ã®è¦‹å‡ºã—åŒ–ï¼‰
        for dt_tag in content_div.find_all('dt'):
            h4_tag = soup.new_tag('h4')
            h4_tag.extend(dt_tag.contents)
            dt_tag.replace_with(h4_tag)

        # 4. HTMLã‹ã‚‰Markdownã¸ã®ä¸€æ¬¡å¤‰æ›
        h = html2text.HTML2Text()
        h.body_width = 0  # ãƒ†ã‚­ã‚¹ãƒˆã®æŠ˜ã‚Šè¿”ã—ã‚’ç„¡åŠ¹ã«ã™ã‚‹
        full_markdown_text = h.handle(str(content_div))

        # 5. ç”Ÿæˆã•ã‚ŒãŸMarkdownã‹ã‚‰ã€Œ## è„šæ³¨ã€ä»¥é™ã‚’å‰Šé™¤
        footnote_marker = "\n## è„šæ³¨"
        footnote_index = full_markdown_text.find(footnote_marker)
        body_text = full_markdown_text[:footnote_index] if footnote_index != -1 else full_markdown_text

        # 6. [ç·¨é›†]ãƒªãƒ³ã‚¯ã‚’æ­£è¦è¡¨ç¾ã§ä¸€æ‹¬å‰Šé™¤
        cleaned_body = re.sub(r'\[\[ç·¨é›†\]\(.+?\)]\n', '', body_text)

        # 7. ã‚¿ã‚¤ãƒˆãƒ«ã¨æ•´å½¢å¾Œã®æœ¬æ–‡ã‚’çµåˆ
        final_markdown = f"# {page_title}\n\n{cleaned_body.strip()}"

        return final_markdown

    except requests.exceptions.RequestException as e:
        return f"HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}"
    except Exception as e:
        return f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

def get_filename_from_url(url):
    """URLã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    try:
        # URLã‹ã‚‰ãƒšãƒ¼ã‚¸åã‚’æŠ½å‡º
        parsed_url = urlparse(url)
        page_name = parsed_url.path.split('/')[-1]
        # URLãƒ‡ã‚³ãƒ¼ãƒ‰
        page_name = unquote(page_name)
        # ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã—ã¦ä½¿ç”¨ã§ããªã„æ–‡å­—ã‚’ç½®æ›
        safe_filename = re.sub(r'[<>:"/\\|?*]', '_', page_name)
        return f"{safe_filename}.md"
    except:
        return "wikipedia_page.md"

def create_download_file(content, filename):
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    try:
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        temp_dir = tempfile.gettempdir()
        file_path = os.path.join(temp_dir, filename)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return file_path
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def create_zip_file(file_paths, zip_filename="wikipedia_export.zip"):
    """è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPå½¢å¼ã§ã¾ã¨ã‚ã‚‹é–¢æ•°"""
    try:
        temp_dir = tempfile.gettempdir()
        zip_path = os.path.join(temp_dir, zip_filename)
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file_path in file_paths:
                if os.path.exists(file_path):
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã‚’å–å¾—ã—ã¦ZIPã«è¿½åŠ 
                    filename = os.path.basename(file_path)
                    zipf.write(file_path, filename)
        
        return zip_path
    except Exception as e:
        print(f"ZIPä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def process_wikipedia_url(url):
    """Wikipedia URLã‚’å‡¦ç†ã—ã¦Markdownã‚’ç”Ÿæˆã™ã‚‹Gradioç”¨é–¢æ•°"""
    if not url:
        return "URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", None
    
    # URLãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
    if not url.startswith('http'):
        return "æœ‰åŠ¹ãªURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆhttp://ã¾ãŸã¯https://ã‹ã‚‰å§‹ã¾ã‚‹URLï¼‰ã€‚", None
    
    # Wikipedia URLã‹ãƒã‚§ãƒƒã‚¯
    if 'wikipedia.org' not in url:
        return "Wikipediaã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", None
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œ
    markdown_content = scrape_wikipedia_to_markdown_final(url)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    if not markdown_content.startswith("ã‚¨ãƒ©ãƒ¼:") and not markdown_content.startswith("HTTP"):
        filename = get_filename_from_url(url)
        file_path = create_download_file(markdown_content, filename)
        return markdown_content, file_path
    else:
        return markdown_content, None

def process_multiple_urls(urls_text, progress=gr.Progress()):
    """è¤‡æ•°ã®Wikipedia URLã‚’ä¸€æ‹¬å‡¦ç†ã—ã¦Markdownã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    if not urls_text.strip():
        return "URLãƒªã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", None, [], None
    
    # URLãƒªã‚¹ãƒˆã‚’è¡Œã”ã¨ã«åˆ†å‰²
    urls = [url.strip() for url in urls_text.strip().split('\n') if url.strip()]
    
    if not urls:
        return "æœ‰åŠ¹ãªURLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", None, [], None
    
    results = []
    all_content = []
    individual_files = []
    total_urls = len(urls)
    success_count = 0
    
    for i, url in enumerate(urls):
        progress((i + 1) / total_urls, f"å‡¦ç†ä¸­: {i + 1}/{total_urls}")
        
        # URLã®æ¤œè¨¼
        if not url.startswith('http'):
            results.append(f"âŒ ç„¡åŠ¹ãªURL: {url}")
            continue
            
        if 'wikipedia.org' not in url:
            results.append(f"âŒ Wikipediaä»¥å¤–ã®URL: {url}")
            continue
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
        try:
            markdown_content = scrape_wikipedia_to_markdown_final(url)
            if markdown_content.startswith("ã‚¨ãƒ©ãƒ¼:") or markdown_content.startswith("HTTP"):
                results.append(f"âŒ å‡¦ç†å¤±æ•—: {url}\n   ã‚¨ãƒ©ãƒ¼: {markdown_content}")
            else:
                # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
                title_match = re.match(r'^# (.+)', markdown_content)
                page_title = title_match.group(1) if title_match else "ä¸æ˜ãªãƒšãƒ¼ã‚¸"
                
                # æ–‡å­—æ•°ã¨ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
                char_count = len(markdown_content)
                filename = get_filename_from_url(url)
                
                results.append(f"âœ… å‡¦ç†æˆåŠŸ: {url}")
                results.append(f"   ğŸ“„ ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: {page_title}")
                results.append(f"   ğŸ“Š æ–‡å­—æ•°: {char_count:,} æ–‡å­—")
                results.append(f"   ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«å: {filename}")
                
                all_content.append(markdown_content)
                success_count += 1
                
                # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                file_path = create_download_file(markdown_content, filename)
                if file_path:
                    individual_files.append(file_path)
        except Exception as e:
            results.append(f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {url}")
            results.append(f"   ã‚¨ãƒ©ãƒ¼å†…å®¹: {str(e)}")
    
    # ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’è¿½åŠ 
    summary = [
        "=" * 60,
        "ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼",
        "=" * 60,
        f"ğŸ”— å‡¦ç†å¯¾è±¡URLæ•°: {total_urls}",
        f"âœ… æˆåŠŸ: {success_count}",
        f"âŒ å¤±æ•—: {total_urls - success_count}",
        ""
    ]
    
    # çµæœã‚’çµåˆ
    final_result = "\n".join(summary + results)
    
    # ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    batch_file_path = None
    if all_content:
        combined_content = "\n\n" + "="*80 + "\n\n".join(all_content)
        batch_file_path = create_download_file(combined_content, "wikipedia_batch_export.md")
    
    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    zip_file_path = None
    if individual_files:
        zip_file_path = create_zip_file(individual_files, "wikipedia_export.zip")
    
    return final_result, batch_file_path, individual_files, zip_file_path

# Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ä½œæˆ
def create_interface():
    """Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    theme = create_zen_theme()
    
    with gr.Blocks(theme=theme, title="Wikipedia to Markdown Converter") as demo:
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        gr.HTML("""
        <div style='text-align: center; margin-bottom: 2rem; padding: 2rem; background: linear-gradient(135deg, #d4a574 0%, #ffffff 50%, #f5f2ed 100%); color: #3d405b; border-radius: 12px;'>
            <h1 style='font-size: 3rem; margin-bottom: 0.5rem; text-shadow: 1px 1px 2px rgba(0,0,0,0.1);'>ğŸ“š Wikipedia to Markdown Converter</h1>
            <p style='font-size: 1.2rem; opacity: 0.8;'>Wikipediaã®URLã‚’å…¥åŠ›ã—ã¦ã€Markdownå½¢å¼ã«å¤‰æ›ã—ã¾ã™</p>
        </div>
        """)
        
        # ã‚¿ãƒ–ã®ä½œæˆ
        with gr.Tabs():
            # å˜ä½“å‡¦ç†ã‚¿ãƒ–
            with gr.TabItem("ğŸ”— å˜ä½“å‡¦ç†"):
                with gr.Row():
                    with gr.Column(scale=1):
                        url_input = gr.Textbox(
                            label="ğŸ”— Wikipedia URL",
                            placeholder="https://ja.wikipedia.org/wiki/...",
                            value="https://ja.wikipedia.org/wiki/Python"
                        )
                        convert_btn = gr.Button("âœ¨ å¤‰æ›ã™ã‚‹", variant="primary")
                    
                    with gr.Column(scale=1):
                        output_text = gr.Textbox(
                            label="ğŸ“ å¤‰æ›ã•ã‚ŒãŸMarkdown",
                            lines=20,
                            max_lines=50,
                            show_copy_button=True
                        )
                        download_file = gr.File(
                            label="ğŸ“¥ ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            visible=False
                        )
                
                # ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯æ™‚ã®å‡¦ç†
                def update_single_output(url):
                    content, file_path = process_wikipedia_url(url)
                    if file_path:
                        return content, gr.update(value=file_path, visible=True)
                    else:
                        return content, gr.update(visible=False)
                
                convert_btn.click(
                    fn=update_single_output,
                    inputs=url_input,
                    outputs=[output_text, download_file]
                )
                
                # ä½¿ç”¨ä¾‹
                def example_process(url):
                    content, _ = process_wikipedia_url(url)
                    return content
                
                gr.Examples(
                    examples=[
                        ["https://ja.wikipedia.org/wiki/Python"],
                        ["https://ja.wikipedia.org/wiki/JavaScript"],
                        ["https://ja.wikipedia.org/wiki/HTML"]
                    ],
                    inputs=url_input,
                    outputs=output_text,
                    fn=example_process,
                    cache_examples=False
                )
            
            # ä¸€æ‹¬å‡¦ç†ã‚¿ãƒ–
            with gr.TabItem("ğŸ“‹ ä¸€æ‹¬å‡¦ç†"):
                with gr.Row():
                    with gr.Column(scale=1):
                        urls_input = gr.Textbox(
                            label="ğŸ“‹ Wikipedia URLãƒªã‚¹ãƒˆï¼ˆ1è¡Œã«1ã¤ãšã¤ï¼‰",
                            placeholder="https://ja.wikipedia.org/wiki/Python\nhttps://ja.wikipedia.org/wiki/JavaScript\nhttps://ja.wikipedia.org/wiki/HTML",
                            lines=10,
                            value="https://ja.wikipedia.org/wiki/Python\nhttps://ja.wikipedia.org/wiki/JavaScript"
                        )
                        batch_convert_btn = gr.Button("ğŸš€ ä¸€æ‹¬å¤‰æ›ã™ã‚‹", variant="primary")
                    
                    with gr.Column(scale=1):
                        batch_output_text = gr.Textbox(
                            label="ğŸ“ ä¸€æ‹¬å¤‰æ›çµæœ",
                            lines=15,
                            max_lines=30,
                            show_copy_button=True
                        )
                        batch_download_file = gr.File(
                            label="ğŸ“¥ å…¨ä½“ã‚’ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            visible=False
                        )
                        zip_download_file = gr.File(
                            label="ğŸ—œï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            visible=False
                        )
                        
                        # å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢
                        individual_downloads = gr.Column(visible=False)
                        with individual_downloads:
                            gr.Markdown("### ğŸ“¥ å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                            individual_file_1 = gr.File(label="", visible=False)
                            individual_file_2 = gr.File(label="", visible=False)
                            individual_file_3 = gr.File(label="", visible=False)
                            individual_file_4 = gr.File(label="", visible=False)
                            individual_file_5 = gr.File(label="", visible=False)
                
                # ä¸€æ‹¬å‡¦ç†ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯æ™‚ã®å‡¦ç†
                def update_batch_output(urls_text):
                    content, batch_file_path, individual_files, zip_file_path = process_multiple_urls(urls_text)
                    
                    # æˆ»ã‚Šå€¤ã®ãƒªã‚¹ãƒˆã‚’æº–å‚™
                    outputs = [content]
                    
                    # ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
                    if batch_file_path:
                        outputs.append(gr.update(value=batch_file_path, visible=True))
                    else:
                        outputs.append(gr.update(visible=False))
                    
                    # ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
                    if zip_file_path:
                        outputs.append(gr.update(value=zip_file_path, visible=True))
                    else:
                        outputs.append(gr.update(visible=False))
                    
                    # å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ã®è¡¨ç¤º/éè¡¨ç¤º
                    if individual_files:
                        outputs.append(gr.update(visible=True))
                    else:
                        outputs.append(gr.update(visible=False))
                    
                    # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæœ€å¤§5ã¤ã¾ã§è¡¨ç¤ºï¼‰
                    for i in range(5):
                        if i < len(individual_files):
                            filename = os.path.basename(individual_files[i])
                            outputs.append(gr.update(value=individual_files[i], visible=True, label=f"ğŸ“„ {filename}"))
                        else:
                            outputs.append(gr.update(visible=False))
                    
                    return outputs
                
                batch_convert_btn.click(
                    fn=update_batch_output,
                    inputs=urls_input,
                    outputs=[
                        batch_output_text, 
                        batch_download_file,
                        zip_download_file,
                        individual_downloads,
                        individual_file_1,
                        individual_file_2,
                        individual_file_3,
                        individual_file_4,
                        individual_file_5
                    ]
                )
                
                gr.Markdown("### ğŸ’¡ ä¸€æ‹¬å‡¦ç†ã®ä½¿ã„æ–¹")
                gr.Markdown("1. ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«å¤‰æ›ã—ãŸã„Wikipediaã®URLã‚’1è¡Œã«1ã¤ãšã¤å…¥åŠ›ã—ã¾ã™")
                gr.Markdown("2. ã€ŒğŸš€ ä¸€æ‹¬å¤‰æ›ã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™")
                gr.Markdown("3. å‡¦ç†ã®é€²è¡ŒçŠ¶æ³ãŒè¡¨ç¤ºã•ã‚Œã€å®Œäº†å¾Œã«çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
                gr.Markdown("4. å„URLã®å‡¦ç†çµæœï¼ˆæˆåŠŸ/å¤±æ•—ï¼‰ãŒæ˜ç¢ºã«è¡¨ç¤ºã•ã‚Œã¾ã™")
        
        gr.Markdown("---")
        gr.Markdown("### ğŸ¯ åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•")
        gr.Markdown("- **å˜ä½“å‡¦ç†**: 1ã¤ã®Wikipediaãƒšãƒ¼ã‚¸ã‚’å¤‰æ›ã—ãŸã„å ´åˆ")
        gr.Markdown("- **ä¸€æ‹¬å‡¦ç†**: è¤‡æ•°ã®Wikipediaãƒšãƒ¼ã‚¸ã‚’ä¸€åº¦ã«å¤‰æ›ã—ãŸã„å ´åˆ")
        gr.Markdown("- ç”Ÿæˆã•ã‚ŒãŸMarkdownã¯å³å´ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã§ãã¾ã™")
        gr.Markdown("- **ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½**: å¤‰æ›ãŒæˆåŠŸã™ã‚‹ã¨ã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™")
        gr.Markdown("  - å˜ä½“å‡¦ç†: ãƒšãƒ¼ã‚¸åã«åŸºã¥ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«åã§å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        gr.Markdown("  - ä¸€æ‹¬å‡¦ç†: å„URLã”ã¨ã®å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ + å…¨ä½“ã‚’ã¾ã¨ã‚ãŸä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ + **ğŸ—œï¸ ZIPãƒ•ã‚¡ã‚¤ãƒ«**")
        gr.Markdown("  - å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: æˆåŠŸã—ãŸå„ãƒšãƒ¼ã‚¸ã‚’å€‹åˆ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ï¼ˆæœ€å¤§5ã¤ã¾ã§è¡¨ç¤ºï¼‰")
        gr.Markdown("  - **ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: è¤‡æ•°ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        # ZENãƒ†ãƒ¼ãƒã®èª¬æ˜
        gr.HTML("""
        <div style='text-align: center; margin-top: 2rem; padding: 1.5rem; background: #ffffff; border-radius: 12px;'>
            <h3 style='color: #3d405b; margin-top: 0;'>ğŸ§˜â€â™€ï¸ ZENãƒ†ãƒ¼ãƒ</h3>
            <p style='color: #8b7355;'>å’Œãƒ¢ãƒ€ãƒ³ãªãƒ‡ã‚¶ã‚¤ãƒ³ã§ã€ä½¿ã„ã‚„ã™ã•ã¨ç¾ã—ã•ã‚’è¿½æ±‚ã—ã¾ã—ãŸ</p>
        </div>
        """)
    
    return demo

if __name__ == "__main__":
    # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½œæˆ
    demo = create_interface()
    
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )
